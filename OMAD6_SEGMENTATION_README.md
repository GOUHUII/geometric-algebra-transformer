# ðŸ¥ OMAD-6 åŒ»å­¦å›¾åƒåˆ†å‰² - GATrå®žçŽ°

åŸºäºŽå‡ ä½•ä»£æ•°å˜æ¢å™¨(Geometric Algebra Transformer)çš„åŒ»å­¦å›¾åƒåˆ†å‰²è§£å†³æ–¹æ¡ˆï¼Œç”¨äºŽOMAD-6æ•°æ®é›†ã€‚

## ðŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ðŸ”¬ å‡ ä½•ä»£æ•°åˆ›æ–°
- **ç»Ÿä¸€è¡¨ç¤º**: å°†2Dåæ ‡å’ŒRGBå€¼åµŒå…¥16ç»´å¤šé‡å‘é‡ç©ºé—´
- **ç­‰å˜æ€§ä¿æŒ**: å¯¹å›¾åƒæ—‹è½¬ã€å¹³ç§»ç­‰å˜æ¢ä¿æŒæ•°å­¦ä¸€è‡´æ€§  
- **å‡ ä½•æ„ŸçŸ¥**: å†…ç½®å‡ ä½•ç»“æž„ç†è§£ï¼Œè¶…è¶Šä¼ ç»ŸCNNæ–¹æ³•

### ðŸš€ æŠ€æœ¯äº®ç‚¹
- **Pin(3,0,1)ç­‰å˜æ€§**: ä¸¥æ ¼çš„æ•°å­¦å¯¹ç§°æ€§ä¿è¯
- **å¤šé‡å‘é‡è¡¨ç¤º**: åæ ‡ç‚¹(trivectors) + RGBæ ‡é‡çš„åˆ›æ–°åµŒå…¥
- **å‡ ä½•æ³¨æ„åŠ›**: ç»“åˆæ¬§å‡ é‡Œå¾—è·ç¦»çš„æ³¨æ„åŠ›æœºåˆ¶
- **åŒæž¶æž„æ”¯æŒ**: æ ‡å‡†GATr + è½´å‘GATrï¼ˆä¸“ä¸º2Då›¾åƒä¼˜åŒ–ï¼‰

## ðŸ“ é¡¹ç›®ç»“æž„

```
geometric-algebra-transformer/
â”œâ”€â”€ gatr/experiments/omad6/          # OMAD-6åˆ†å‰²å®žçŽ°
â”‚   â”œâ”€â”€ dataset.py                   # æ•°æ®åŠ è½½å™¨ï¼ˆCOCOæ ¼å¼æ”¯æŒï¼‰
â”‚   â”œâ”€â”€ wrappers.py                  # GATråŒ…è£…å™¨ï¼ˆæ ‡å‡†ç‰ˆ+è½´å‘ç‰ˆï¼‰
â”‚   â”œâ”€â”€ experiment.py                # å®žéªŒç®¡ç†å™¨
â”‚   â””â”€â”€ utils.py                     # å¯è§†åŒ–å’Œè¯„ä¼°å·¥å…·
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ omad6.yaml                   # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ gatr_omad6.yaml          # æ ‡å‡†GATré…ç½®
â”‚       â””â”€â”€ axial_gatr_omad6.yaml    # è½´å‘GATré…ç½®
â”œâ”€â”€ scripts/omad6_experiment.py      # å®žéªŒè„šæœ¬
â”œâ”€â”€ demo_omad6_segmentation.py       # æ¼”ç¤ºè„šæœ¬
â””â”€â”€ data/OMAD-6/                     # æ•°æ®é›†ç›®å½•
    â”œâ”€â”€ train2017/                   # è®­ç»ƒå›¾åƒ
    â”œâ”€â”€ val2017/                     # éªŒè¯å›¾åƒ
    â”œâ”€â”€ test2017/                    # æµ‹è¯•å›¾åƒ
    â””â”€â”€ annotations/                 # COCOæ ¼å¼æ ‡æ³¨
```

## ðŸ”§ çŽ¯å¢ƒè¦æ±‚

```bash
# åŸºç¡€ä¾èµ–
torch>=2.0
einops  
numpy<1.25
opt_einsum
xformers

# å›¾åƒå¤„ç†
PIL
torchvision

# å®žéªŒç®¡ç†
hydra-core
omegaconf
mlflow

# å¯è§†åŒ–
matplotlib
```

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ•°æ®å‡†å¤‡
ç¡®ä¿OMAD-6æ•°æ®é›†åœ¨æ­£ç¡®ä½ç½®ï¼š
```
data/OMAD-6/
â”œâ”€â”€ train2017/           # è®­ç»ƒå›¾åƒ (PNGæ ¼å¼)
â”œâ”€â”€ val2017/             # éªŒè¯å›¾åƒ  
â”œâ”€â”€ test2017/            # æµ‹è¯•å›¾åƒ
â””â”€â”€ annotations/         # COCOæ ¼å¼æ ‡æ³¨
    â”œâ”€â”€ instances_train2017.json
    â””â”€â”€ instances_val2017.json
```

### 2. è¿è¡Œæ¼”ç¤º
```bash
# äº¤äº’å¼æ¼”ç¤º
python demo_omad6_segmentation.py

# æˆ–ç›´æŽ¥è¿è¡Œå®žéªŒ
python scripts/omad6_experiment.py base_dir="/path/to/experiments" seed=42
```

### 3. è®­ç»ƒæ¨¡åž‹

#### ðŸŽ¯ æ ‡å‡†GATrï¼ˆæŽ¨èæ–°æ‰‹ï¼‰
```bash
python scripts/omad6_experiment.py \
    base_dir="${BASEDIR}" \
    seed=42 \
    model=gatr_omad6 \
    training.steps=5000 \
    training.batchsize=2 \
    run_name=gatr_basic
```

#### ðŸŽ¯ è½´å‘GATrï¼ˆæ›´é€‚åˆ2Då›¾åƒï¼‰
```bash
python scripts/omad6_experiment.py \
    base_dir="${BASEDIR}" \
    seed=42 \
    model=axial_gatr_omad6 \
    training.steps=5000 \
    training.batchsize=2 \
    run_name=axial_gatr
```

#### ðŸŽ¯ å¿«é€Ÿæµ‹è¯•ï¼ˆ10%æ•°æ®ï¼‰
```bash
python scripts/omad6_experiment.py \
    base_dir="${BASEDIR}" \
    seed=42 \
    data.subsample=0.1 \
    training.steps=1000 \
    run_name=quick_test
```

## ðŸ§  æŠ€æœ¯åŽŸç†

### å‡ ä½•ä»£æ•°åµŒå…¥ç­–ç•¥

#### ðŸ”¹ åƒç´ æ•°æ®è¡¨ç¤º
```python
# è¾“å…¥ï¼šåƒç´ æ•°æ® [x, y, R, G, B]
# åæ ‡èŒƒå›´ï¼š[-1, 1], RGBèŒƒå›´ï¼š[0, 1]

# 1. 2Dåæ ‡æ‰©å±•ä¸º3Dç‚¹ï¼ˆz=0ï¼‰
coordinates_3d = [x, y, 0]
point_embedding = embed_point(coordinates_3d)  # trivectorè¡¨ç¤º

# 2. RGBå€¼åµŒå…¥ä¸ºæ ‡é‡
r_scalar = embed_scalar([R])
g_scalar = embed_scalar([G])  
b_scalar = embed_scalar([B])

# 3. å¤šé€šé“å¤šé‡å‘é‡
multivector = stack([point_embedding, r_scalar, g_scalar, b_scalar])
# å½¢çŠ¶ï¼š(batch, pixels, 4_channels, 16_dimensions)
```

#### ðŸ”¹ å‡ ä½•æ³¨æ„åŠ›æœºåˆ¶
```python
# ç»“åˆä¸‰ç§ç›¸ä¼¼åº¦è®¡ç®—ï¼š
# 1. PGAå†…ç§¯ï¼ˆå‡ ä½•å…³ç³»ï¼‰
# 2. æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆç©ºé—´ä½ç½®ï¼‰
# 3. éžçº¿æ€§ç‰¹å¾ï¼ˆRGBç›¸ä¼¼æ€§ï¼‰

attention_weights = softmax(
    pga_inner_product(q_mv, k_mv) +
    euclidean_distance(q_s, k_s) +
    nonlinear_features(phi(q_s), psi(k_s))
)
```

### ç½‘ç»œæž¶æž„å¯¹æ¯”

| ç‰¹æ€§ | æ ‡å‡†GATr | è½´å‘GATr |
|------|----------|----------|
| **é€‚ç”¨åœºæ™¯** | é€šç”¨åˆ†å‰² | 2Då›¾åƒç‰¹åŒ– |
| **è®¡ç®—å¤æ‚åº¦** | O(nÂ²) | O(nâˆšn) |
| **ç©ºé—´æ„ŸçŸ¥** | å…¨å±€æ³¨æ„åŠ› | è¡Œåˆ—åˆ†ç¦»æ³¨æ„åŠ› |
| **å†…å­˜ä½¿ç”¨** | è¾ƒé«˜ | è¾ƒä½Ž |
| **æŽ¨èç”¨é€”** | å°å›¾åƒã€é«˜ç²¾åº¦ | å¤§å›¾åƒã€é«˜æ•ˆçŽ‡ |

## ðŸ“Š è¯„ä¼°æŒ‡æ ‡

### ðŸŽ¯ ä¸»è¦æŒ‡æ ‡
- **mIoU (å¹³å‡IoU)**: å„ç±»åˆ«IoUçš„å¹³å‡å€¼
- **æ•´ä½“å‡†ç¡®çŽ‡**: åƒç´ çº§åˆ†ç±»å‡†ç¡®çŽ‡
- **ç±»åˆ«IoU**: æ¯ä¸ªè§£å‰–ç»“æž„çš„åˆ†å‰²è´¨é‡

### ðŸŽ¯ é¢„æœŸæ€§èƒ½
```
æ ‡å‡†GATr:
â”œâ”€â”€ mIoU: ~0.75-0.85 (å–å†³äºŽæ•°æ®è´¨é‡)
â”œâ”€â”€ å‡†ç¡®çŽ‡: ~0.85-0.95
â””â”€â”€ è®­ç»ƒæ—¶é—´: ~2-4å°æ—¶ (RTX 3080)

è½´å‘GATr:
â”œâ”€â”€ mIoU: ~0.70-0.80
â”œâ”€â”€ å‡†ç¡®çŽ‡: ~0.80-0.90  
â””â”€â”€ è®­ç»ƒæ—¶é—´: ~1-2å°æ—¶ (å†…å­˜æ•ˆçŽ‡æ›´é«˜)
```

## ðŸ”¬ å®žéªŒé…ç½®è¯¦è§£

### æ•°æ®é…ç½® (`config/omad6.yaml`)
```yaml
data:
  image_size: 256        # å›¾åƒå°ºå¯¸
  max_items: 1024        # æ¯å›¾æœ€å¤§åƒç´ æ•°ï¼ˆå†…å­˜æŽ§åˆ¶ï¼‰
  num_classes: 11        # åˆ†å‰²ç±»åˆ«æ•°ï¼ˆå«èƒŒæ™¯ï¼‰
  subsample: null        # æ•°æ®å­é‡‡æ ·çŽ‡
```

### æ¨¡åž‹é…ç½® (`config/model/gatr_omad6.yaml`)
```yaml
net:
  in_mv_channels: 4      # è¾“å…¥ï¼šç‚¹+R+G+B
  out_mv_channels: 1     # è¾“å‡ºï¼šåˆ†å‰²ç‰¹å¾
  hidden_mv_channels: 32 # éšè—å±‚å®½åº¦
  num_blocks: 8          # Transformerå—æ•°
  attention:
    num_heads: 4         # æ³¨æ„åŠ›å¤´æ•°
    hidden_dim: 256      # æ³¨æ„åŠ›ç»´åº¦
  dropout_prob: 0.1      # DropoutçŽ‡
```

### è®­ç»ƒé…ç½®
```yaml
training:
  lr: 1e-4              # å­¦ä¹ çŽ‡ï¼ˆè¾ƒä¿å®ˆï¼‰
  batchsize: 2          # æ‰¹æ¬¡å¤§å°ï¼ˆå†…å­˜é™åˆ¶ï¼‰
  steps: 10000          # è®­ç»ƒæ­¥æ•°
  weight_decay: 1e-4    # æƒé‡è¡°å‡
  clip_grad_norm: 1.0   # æ¢¯åº¦è£å‰ª
```

## ðŸŽ¨ å¯è§†åŒ–åŠŸèƒ½

### ç»“æžœå¯è§†åŒ–
```python
from gatr.experiments.omad6.utils import visualize_segmentation_results

# å¯è§†åŒ–åˆ†å‰²ç»“æžœ
visualize_segmentation_results(
    image=original_image,
    ground_truth=gt_mask,
    prediction=pred_mask,
    save_path="./results/segmentation_comparison.png"
)
```

### è®­ç»ƒç›‘æŽ§
- **MLflowè·Ÿè¸ª**: è‡ªåŠ¨è®°å½•æŸå¤±ã€æŒ‡æ ‡ã€å‚æ•°
- **å®žæ—¶æ—¥å¿—**: è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
- **æ£€æŸ¥ç‚¹ä¿å­˜**: è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡åž‹

## ðŸš€ é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰æ•°æ®é›†
```python
# ç»§æ‰¿OMAD6Datasetç±»
class CustomMedicalDataset(OMAD6Dataset):
    def _create_segmentation_mask(self, image_id, image_shape):
        # å®žçŽ°è‡ªå®šä¹‰çš„æŽ©ç ç”Ÿæˆé€»è¾‘
        pass
```

### 2. æ¨¡åž‹è°ƒä¼˜
```bash
# è°ƒæ•´ç½‘ç»œæ·±åº¦
python scripts/omad6_experiment.py model.net.num_blocks=12

# è°ƒæ•´æ³¨æ„åŠ›å¤´æ•°
python scripts/omad6_experiment.py model.net.attention.num_heads=8

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœå†…å­˜ï¼‰
python scripts/omad6_experiment.py model.net.checkpoint='["block"]'
```

### 3. å¤šGPUè®­ç»ƒ
```bash
# ä½¿ç”¨æ•°æ®å¹¶è¡Œ
export CUDA_VISIBLE_DEVICES=0,1
python scripts/omad6_experiment.py training.batchsize=8
```

## ðŸ” æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

#### ðŸ› å†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. å‡å°‘æ‰¹æ¬¡å¤§å°
training.batchsize=1

# 2. å‡å°‘æœ€å¤§åƒç´ æ•°
data.max_items=512

# 3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.net.checkpoint='["block"]'
```

#### ðŸ› æ”¶æ•›æ…¢
```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. è°ƒæ•´å­¦ä¹ çŽ‡
training.lr=3e-4

# 2. å‡å°‘æƒé‡è¡°å‡
training.weight_decay=1e-5

# 3. ä½¿ç”¨å­¦ä¹ çŽ‡è°ƒåº¦
training.lr_decay=0.5
```

#### ðŸ› è¿‡æ‹Ÿåˆ
```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. å¢žåŠ Dropout
model.net.dropout_prob=0.2

# 2. å¢žåŠ æƒé‡è¡°å‡
training.weight_decay=1e-3

# 3. ä½¿ç”¨æ•°æ®å¢žå¼º
data.augmentation=true
```

## ðŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### ðŸš€ è®­ç»ƒåŠ é€Ÿ
1. **ä½¿ç”¨æ··åˆç²¾åº¦**: `training.float16=true`
2. **ç¼–è¯‘æ¨¡åž‹**: `torch.compile(model)`
3. **é¢„è®¡ç®—åµŒå…¥**: ç¼“å­˜åƒç´ åµŒå…¥ç»“æžœ
4. **æ‰¹å¤„ç†ä¼˜åŒ–**: åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´

### ðŸ§  å†…å­˜ä¼˜åŒ–
1. **æ¢¯åº¦æ£€æŸ¥ç‚¹**: ä»¥è®¡ç®—æ¢å†…å­˜
2. **åƒç´ é‡‡æ ·**: éšæœºé‡‡æ ·å‡å°‘å†…å­˜ä½¿ç”¨
3. **æ¨¡åž‹è’¸é¦**: è®­ç»ƒè¾ƒå°çš„å­¦ç”Ÿæ¨¡åž‹
4. **é‡åŒ–æŽ¨ç†**: 8ä½æ•´æ•°æŽ¨ç†

## ðŸŽ¯ æ‰©å±•æ–¹å‘

### ðŸ”¬ ç ”ç©¶æ‰©å±•
- **3DåŒ»å­¦å›¾åƒ**: æ‰©å±•åˆ°CT/MRIä½“æ•°æ®
- **å¤šæ¨¡æ€èžåˆ**: ç»“åˆæ–‡æœ¬ã€å›¾åƒã€ä¸´åºŠæ•°æ®
- **åœ¨çº¿å­¦ä¹ **: å¢žé‡å­¦ä¹ æ–°çš„è§£å‰–ç»“æž„
- **ä¸ç¡®å®šæ€§é‡åŒ–**: è´å¶æ–¯GATrå˜ç§

### ðŸ¥ ä¸´åºŠåº”ç”¨
- **å®žæ—¶åˆ†å‰²**: æ‰‹æœ¯å¯¼èˆªç³»ç»Ÿ
- **ç–¾ç—…è¯Šæ–­**: ç—…å˜åŒºåŸŸè‡ªåŠ¨æ£€æµ‹
- **æ²»ç–—è§„åˆ’**: æ”¾ç–—é¶åŒºå‹¾ç”»
- **è´¨é‡æŽ§åˆ¶**: åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°

## ðŸ“š å‚è€ƒæ–‡çŒ®

1. **Geometric Algebra Transformer**: [NeurIPS 2023](https://arxiv.org/abs/2305.18415)
2. **æŠ•å½±å‡ ä½•ä»£æ•°**: Dorst, "A Guided Tour to the Plane-Based Geometric Algebra PGA"
3. **åŒ»å­¦å›¾åƒåˆ†å‰²**: Comprehensive survey of deep learning approaches

## ðŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿Žè´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ï¼

### å¼€å‘æµç¨‹
1. Forké¡¹ç›®ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. ç¼–å†™æµ‹è¯•ç”¨ä¾‹
4. æäº¤Pull Request

### ä»£ç è§„èŒƒ
- éµå¾ªPEP 8é£Žæ ¼
- æ·»åŠ ç±»åž‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- ç¡®ä¿æµ‹è¯•é€šè¿‡

## ðŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºŽQualcomm Technologies, Inc.çš„è®¸å¯è¯å‘å¸ƒã€‚

---

ðŸš€ **å¼€å§‹ä½ çš„å‡ ä½•ä»£æ•°å›¾åƒåˆ†å‰²ä¹‹æ—…ï¼** 

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹issuesæˆ–è”ç³»ç»´æŠ¤è€…ã€‚